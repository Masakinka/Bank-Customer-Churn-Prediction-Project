# Bank Customer Churn Prediction Project

This project is focused on predicting customer churn in the banking sector using various machine learning techniques. It was part of a Kaggle competition, **["Bank Customer Churn Prediction (DLU Course)"](https://www.kaggle.com/competitions/bank-customer-churn-prediction-dlu)**, where I secured **3rd place** with a score of **0.93265** on the private leaderboard. The goal of the project was to predict whether a customer would subscribe to a term deposit based on demographic and transactional data.

## Highlights
- **Kaggle Competition**: Completed as part of the Kaggle "Bank Customer Churn Prediction (DLU Course)" competition.
- **3rd Place Finish**: Achieved 3rd place in the final standings, demonstrating strong model performance and data analysis.
- **Comprehensive Machine Learning Techniques**: Utilized a range of algorithms, including logistic regression, decision trees, k-Nearest Neighbors (k-NN), and boosting methods.

## Project Structure

This project consists of five key notebooks, each focusing on different machine learning approaches:

### 1. Logistic Regression with scikit-learn
- **Notebook**: `01_Logistic_Regression_with_scikit-learn.ipynb`
- **Key Focus**:
  - Implemented logistic regression using `scikit-learn`.
  - Preprocessing data, feature scaling, and evaluating performance with precision, recall, and F1-scores.

### 2. Polynomial Features and Pipelines for Model Enhancement
- **Notebook**: `02_Polynomial_Features_and_Pipelines.ipynb`
- **Key Focus**:
  - Applied polynomial features to enhance model complexity.
  - Built end-to-end pipelines for efficient preprocessing and model training.
  - Conducted hyperparameter tuning with cross-validation.

### 3. Decision Trees for Classification
- **Notebook**: `03_Decision_Trees_for_Classification.ipynb`
- **Key Focus**:
  - Utilized Decision Tree algorithms for classification tasks.
  - Visualized decision-making paths and optimized tree depth.

### 4. k-Nearest Neighbors (k-NN) with Hyperparameter Tuning
- **Notebook**: `04_kNN_with_Hyperparameter_Tuning.ipynb`
- **Key Focus**:
  - Implemented the k-NN algorithm.
  - Tuned hyperparameters using cross-validation and grid search.
  - Evaluated model performance using confusion matrices and classification metrics.

### 5. Boosting Algorithms for Model Improvement
- **Notebook**: `05_Boosting_Algorithms_for_Model_Improvement.ipynb`
- **Key Focus**:
  - Explored boosting algorithms such as Gradient Boosting and AdaBoost.
  - Tuned hyperparameters to improve model performance.
  - Compared model improvements with previous algorithms.

### Python Script for Data Processing
- **Script**: `process_bank_churn.py`
- **Key Focus**:
  - Script handles data preprocessing, including handling missing values, feature extraction, and scaling.
  - Prepares data for modeling across all notebooks.

## Key Project Insights
- **Data Preprocessing**: Extensive work on cleaning the dataset, handling missing values, and transforming features to ensure model accuracy.
- **Model Selection**: Tested and optimized multiple machine learning models to find the best-performing algorithm for predicting customer churn.
- **Performance Optimization**: Applied techniques such as cross-validation, grid search, and hyperparameter tuning to optimize each model.
- **Leaderboard Ranking**: Achieved 3rd place on the private leaderboard of the Kaggle competition, demonstrating effective model generalization on unseen data.

## Kaggle Competition Details
- **Competition Name**: [Bank Customer Churn Prediction (DLU Course)](https://www.kaggle.com/competitions/bank-customer-churn-prediction-dlu)
- **Leaderboard Ranking**: 3rd Place
- **Score**: 0.93265

## Conclusion
